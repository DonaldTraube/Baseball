import pandas as pd
import requests
from datetime import date, timedelta
from bs4 import BeautifulSoup
import lxml
import numpy as np
import csv

#Pitch Scrape
def parse_array_from_fangraphs_html(start_date,end_date, URL_1):
    """
    Take a HTML stats page from fangraphs and parse it out to a dataframe.
    """
    # parse input
    PITCHERS_URL = URL_1
    # request data
    pitchers_html = requests.get(PITCHERS_URL).text
    soup = BeautifulSoup(pitchers_html, "lxml")
    table = soup.find("table", {"class": "rgMasterTable"})
    
    # get headers
    headers_html = table.find("thead").find_all("th")
    headers = []
    for header in headers_html:
        headers.append(header.text)

    # get rows
    rows = []
    rows_html = table.find("tbody").find_all("tr")
    for row in rows_html:
        row_data = []
        for cell in row.find_all("td"):
            row_data.append(cell.text)
        rows.append(row_data)
    
    return pd.DataFrame(rows, columns = headers)

sdate = '2024-03-01'
enddate = '2024-04-08'

#date.today() - timedelta(1)
#enddate = enddate.strftime("%Y-%m-%d")
PITCHERS = "https://www.fangraphs.com/leaders-legacy.aspx?pos=all&stats=pit&lg=all&qual=0&type=c,13,7,16,42,59&season=2023&month=1000&season1=2023&ind=0&team=0,ts&rost=0&age=0&filter=&players=0&startdate=2024-03-01&enddate=2024-07-15&v_cr=legacy".format(sdate, enddate)

wRC1 = parse_array_from_fangraphs_html(sdate, enddate, PITCHERS)

#Batter Scrape
def parse_array_from_fangraphs_html(start_date,end_date, URL_2):
    """
    Take a HTML stats page from fangraphs and parse it out to a dataframe.
    """
    # parse input
    BATTERS_URL = URL_2
    # request the data
    batters_html = requests.get(BATTERS_URL).text
    soup = BeautifulSoup(batters_html, "lxml")
    table = soup.find("table", {"class": "rgMasterTable"})
    
    # get headers
    headers_html = table.find("thead").find_all("th")
    headers = []
    for header in headers_html:
        headers.append(header.text)

    # get rows
    rows = []
    rows_html = table.find("tbody").find_all("tr")
    for row in rows_html:
        row_data = []
        for cell in row.find_all("td"):
            row_data.append(cell.text)
        rows.append(row_data)
    
    return pd.DataFrame(rows, columns = headers)

sdate = '2024-03-01'
enddate = '20240715'

#date.today() - timedelta(1)
#enddate = enddate.strftime("%Y-%m-%d")
BATTERS = "https://www.fangraphs.com/leaders-legacy.aspx?pos=all&stats=bat&lg=all&qual=0&type=c%2C5%2C4%2C12%2C39%2C58&season=2023&month=1000&season1=2023&ind=0&team=0%2Cts&rost=0&age=0&filter=&players=0&startdate=2024-03-01&enddate=2024-07-15".format(sdate, enddate)

wRC2 = parse_array_from_fangraphs_html(sdate, enddate, BATTERS)

print (wRC1)
print (wRC2)

#print to csv
DPD = wRC1
DBD = wRC2
df = pd.DataFrame(DPD)
df2 = pd.DataFrame(DBD)

df.to_csv("P"+enddate+".csv",index=False)
df2.to_csv("B"+enddate+".csv",index=False)
